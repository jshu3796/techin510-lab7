{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp39-cp39-macosx_12_0_arm64.whl (10.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.5 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Pillow\n",
      "  Using cached pillow-10.3.0-cp39-cp39-macosx_11_0_arm64.whl (3.4 MB)\n",
      "Collecting transformers<5.0.0,>=4.34.0\n",
      "  Using cached transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.13.0-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.3 MB 38.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Collecting torch>=1.11.0\n",
      "  Downloading torch-2.3.0-cp39-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 61.0 MB 31.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub>=0.15.1\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/miko/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 19.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /Users/miko/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 51.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.4.28-cp39-cp39-macosx_11_0_arm64.whl (278 kB)\n",
      "\u001b[K     |████████████████████████████████| 278 kB 22.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp39-cp39-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 15.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.3-cp39-cp39-macosx_11_0_arm64.whl (411 kB)\n",
      "\u001b[K     |████████████████████████████████| 411 kB 16.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_universal2.whl (18 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-macosx_11_0_arm64.whl (120 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, tqdm, requests, pyyaml, fsspec, filelock, numpy, mpmath, MarkupSafe, huggingface-hub, tokenizers, threadpoolctl, sympy, scipy, safetensors, regex, networkx, joblib, jinja2, transformers, torch, scikit-learn, Pillow, sentence-transformers\n",
      "Successfully installed MarkupSafe-2.1.5 Pillow-10.3.0 certifi-2024.2.2 charset-normalizer-3.3.2 filelock-3.14.0 fsspec-2024.3.1 huggingface-hub-0.23.0 idna-3.7 jinja2-3.1.4 joblib-1.4.2 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.4 pyyaml-6.0.1 regex-2024.4.28 requests-2.31.0 safetensors-0.4.3 scikit-learn-1.4.2 scipy-1.13.0 sentence-transformers-2.7.0 sympy-1.12 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.3.0 tqdm-4.66.4 transformers-4.40.2 urllib3-2.2.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp39-cp39-macosx_11_0_arm64.whl (923 kB)\n",
      "\u001b[K     |████████████████████████████████| 923 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /Users/miko/Library/Python/3.9/lib/python/site-packages (from tiktoken) (2024.4.28)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/miko/Library/Python/3.9/lib/python/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/miko/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/miko/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/miko/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/miko/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.6.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name Supabase/gte-small. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7975]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "sentences = [\n",
    "    'The new book is bad',\n",
    "    'This recent sentence is so crazy',\n",
    "]\n",
    "\n",
    "model = SentenceTransformer('Supabase/gte-small')\n",
    "embeddings = model.encode(sentences)\n",
    "print(cos_sim(embeddings[0], embeddings[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dog plays in the garden \t\t The dog plays in the garden \t\t Score: 1.0000\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: 0.7016\n",
      "sdgwaokdfbhas hosiuhdasdbc \t\t The new movie is so great \t\t Score: 0.7146\n"
     ]
    }
   ],
   "source": [
    "# Two lists of sentences\n",
    "sentences1 = [\n",
    "    \"The dog plays in the garden\",\n",
    "    \"A man is playing guitar\",\n",
    "    \"sdgwaokdfbhas hosiuhdasdbc\",\n",
    "]\n",
    "\n",
    "sentences2 = [\n",
    "    \"The dog plays in the garden\",\n",
    "    \"A woman watches TV\",\n",
    "    \"The new movie is so great\",\n",
    "]\n",
    "\n",
    "# Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine-similarities\n",
    "cosine_scores = cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "# Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(\n",
    "        sentences1[i], sentences2[i], cosine_scores[i][i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def split_large_text(large_text, max_tokens):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokenized_text = enc.encode(large_text)\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for token in tokenized_text:\n",
    "        current_chunk.append(token)\n",
    "        current_length += 1\n",
    "\n",
    "        if current_length >= max_tokens:\n",
    "            chunks.append(enc.decode(current_chunk).rstrip(' .,;'))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(enc.decode(current_chunk).rstrip(' .,;'))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "12\n",
      "[b'test', b' how', b' it', b' will', b' count', b' words', b' if', b'ip', b'ut', b'them', b'to', b'gether']\n",
      "12\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test how it will count words ifiputthemtogether'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "sent = \"test how it will count words ifiputthemtogether\"\n",
    "\n",
    "print(len(sent.split()))\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoded = enc.encode(sent)\n",
    "print(len(encoded))\n",
    "tokens = [enc.decode_single_token_bytes(x) for x in encoded]\n",
    "print(tokens)\n",
    "print(len(tokens))\n",
    "decoded = enc.decode(encoded)\n",
    "print(len(decoded.split()))\n",
    "decoded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
